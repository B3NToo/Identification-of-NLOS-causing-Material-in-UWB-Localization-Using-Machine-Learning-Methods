{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Import modules from Scikit-learn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split   # Import train_test_split function\n",
    "from sklearn import metrics   # import metrics modules for accuracy calculation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "PATH = \"../../my_data/identification-dataset/my_custom_data/anblock-error-dataset.csv\"\n",
    "df = pd.read_csv(PATH)\n",
    "\n",
    "# Drop uncomplete rows\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training data\n",
    "train_df = df.drop('material', axis=1)\n",
    "\n",
    "# Extracted features \n",
    "X = train_df.drop('encoded_material', axis=1)\n",
    "y = train_df['encoded_material'] # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different variations of hidden layer combinations\n",
    "hidden_layers_50 = [(50,), (50, 50), (50, 50, 50), (50, 50, 50, 50), (50, 50, 50, 50, 50), (50, 50, 50, 50, 50, 50)]\n",
    "hidden_layers_100 = [(100,), (100, 100), (100, 100, 100), (100, 100, 100, 100), (100, 100, 100, 100, 100), (100, 100, 100, 100, 100, 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store results\n",
    "def trainer(hidden_layer_sizes_list):\n",
    "    results = []\n",
    "    for sizes in hidden_layer_sizes_list:\n",
    "        # Create a pipeline object for the model\n",
    "        pipe_MLP = make_pipeline(StandardScaler(),\n",
    "                                MLPClassifier(solver='adam',\n",
    "                                            activation='relu',\n",
    "                                            \n",
    "                                            hidden_layer_sizes=sizes,\n",
    "                                            random_state=0,\n",
    "                                            max_iter=500           # TODO: tune it later\n",
    "                                            # verbose=True\n",
    "                                            )\n",
    "                                )\n",
    "        \n",
    "        # Measure training time\n",
    "        start_train = time.time()\n",
    "        pipe_MLP.fit(X_train, y_train)\n",
    "        end_train = time.time()\n",
    "        train_time_per_sample = (end_train - start_train) / len(X_train)\n",
    "\n",
    "        # Measure test time\n",
    "        start_test = time.time()\n",
    "        y_pred = pipe_MLP.predict(X_test)\n",
    "        end_test = time.time()\n",
    "        test_time_per_sample = (end_test - start_test) / len(X_test)\n",
    "        \n",
    "        # Evaluate the pipeline and store the results\n",
    "        accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "        precision = metrics.precision_score(y_test, y_pred, average=\"macro\")\n",
    "        recall = metrics.recall_score(y_test, y_pred, average=\"macro\")\n",
    "        f1 = metrics.recall_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "\n",
    "        results.append({\n",
    "            'hidden_layer_sizes': sizes,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'train_time_per_sample': train_time_per_sample,\n",
    "            'test_time_per_sample': test_time_per_sample \n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bentmeemken/miniconda3/envs/dataScience/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/bentmeemken/miniconda3/envs/dataScience/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/bentmeemken/miniconda3/envs/dataScience/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/bentmeemken/miniconda3/envs/dataScience/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/bentmeemken/miniconda3/envs/dataScience/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/bentmeemken/miniconda3/envs/dataScience/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/bentmeemken/miniconda3/envs/dataScience/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/bentmeemken/miniconda3/envs/dataScience/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/bentmeemken/miniconda3/envs/dataScience/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/bentmeemken/miniconda3/envs/dataScience/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for x in np.arange(10):\n",
    "    r = trainer(hidden_layer_sizes_list = hidden_layers_50)\n",
    "    results.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_layer_sizes</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>train_time_per_sample</th>\n",
       "      <th>test_time_per_sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.981860</td>\n",
       "      <td>0.982025</td>\n",
       "      <td>0.982028</td>\n",
       "      <td>0.982028</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>5.787000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(50, 50)</td>\n",
       "      <td>0.991154</td>\n",
       "      <td>0.991350</td>\n",
       "      <td>0.991123</td>\n",
       "      <td>0.991123</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>1.333187e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(50, 50, 50)</td>\n",
       "      <td>0.988019</td>\n",
       "      <td>0.988097</td>\n",
       "      <td>0.988220</td>\n",
       "      <td>0.988220</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>1.565933e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(50, 50, 50, 50)</td>\n",
       "      <td>0.980460</td>\n",
       "      <td>0.981017</td>\n",
       "      <td>0.980441</td>\n",
       "      <td>0.980441</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>2.899774e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(50, 50, 50, 50, 50)</td>\n",
       "      <td>0.980404</td>\n",
       "      <td>0.980523</td>\n",
       "      <td>0.980583</td>\n",
       "      <td>0.980583</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>3.198421e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(50, 50, 50, 50, 50, 50)</td>\n",
       "      <td>0.983875</td>\n",
       "      <td>0.983930</td>\n",
       "      <td>0.984097</td>\n",
       "      <td>0.984097</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>4.615864e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         hidden_layer_sizes  accuracy  precision    recall        f1  \\\n",
       "0                     (50,)  0.981860   0.982025  0.982028  0.982028   \n",
       "1                  (50, 50)  0.991154   0.991350  0.991123  0.991123   \n",
       "2              (50, 50, 50)  0.988019   0.988097  0.988220  0.988220   \n",
       "3          (50, 50, 50, 50)  0.980460   0.981017  0.980441  0.980441   \n",
       "4      (50, 50, 50, 50, 50)  0.980404   0.980523  0.980583  0.980583   \n",
       "5  (50, 50, 50, 50, 50, 50)  0.983875   0.983930  0.984097  0.984097   \n",
       "\n",
       "   train_time_per_sample  test_time_per_sample  \n",
       "0               0.001395          5.787000e-07  \n",
       "1               0.001290          1.333187e-06  \n",
       "2               0.000961          1.565933e-06  \n",
       "3               0.000819          2.899774e-06  \n",
       "4               0.000880          3.198421e-06  \n",
       "5               0.001450          4.615864e-06  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show one of 10 samples\n",
    "results_df = pd.DataFrame(results[0])\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
