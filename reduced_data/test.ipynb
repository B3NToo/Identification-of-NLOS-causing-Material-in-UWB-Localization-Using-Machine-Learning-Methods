{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules from Scikit-learn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split   # Import train_test_split function\n",
    "from sklearn import metrics   # import metrics modules for accuracy calculation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "PATH = \"../../my_data/identification-dataset/my_custom_data/big-identification-dataset.csv\"\n",
    "df = pd.read_csv(PATH)\n",
    "\n",
    "# shuffle the data\n",
    "# df = shuffle(df)\n",
    "\n",
    "# drop NaN values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data subsets\n",
    "df_10p = df.sample(frac = 0.1, random_state = 200)\n",
    "df_20p = df.sample(frac = 0.2, random_state = 200)\n",
    "df_30p = df.sample(frac = 0.3, random_state = 200)\n",
    "df_40p = df.sample(frac = 0.4, random_state = 200)\n",
    "df_50p = df.sample(frac = 0.5, random_state = 200)\n",
    "df_60p = df.sample(frac = 0.6, random_state = 200)\n",
    "df_70p = df.sample(frac = 0.7, random_state = 200)\n",
    "df_80p = df.sample(frac = 0.8, random_state = 200)\n",
    "df_90p = df.sample(frac = 0.9, random_state = 200)\n",
    "\n",
    "subsets = [df_10p, df_20p, df_30p, df_40p, df_50p, df_60p, df_70p, df_80p, df_90p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95792\n",
      "191592\n",
      "287384\n",
      "383184\n",
      "478976\n",
      "574768\n",
      "670568\n",
      "766360\n",
      "862160\n"
     ]
    }
   ],
   "source": [
    "for d in subsets:\n",
    "    print(d.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline object for the model\n",
    "pipe_MLP = make_pipeline(StandardScaler(),\n",
    "                         MLPClassifier(solver='adam',\n",
    "                                       hidden_layer_sizes=(100,100,100,), # 3 hidden layers with (100x100x100) neurons\n",
    "                                       random_state=0,\n",
    "                                       max_iter=500           # TODO: tune it later\n",
    "                                       )\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracted features \n",
    "X = df_10p[['tdoa', 'snr_an', 'power_dif', 'rx_snr', 'rx_powerdif', 'tof']]\n",
    "y = df_10p['NLOS_material'] # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('mlpclassifier',\n",
       "                 MLPClassifier(hidden_layer_sizes=(100, 100, 100), max_iter=500,\n",
       "                               random_state=0))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the whole pipeline\n",
    "pipe_MLP.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = pipe_MLP.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 86.33453938213192%\n"
     ]
    }
   ],
   "source": [
    "# Caluclate the accuracy on test data predicitons\n",
    "print(f'Test Accuracy: {metrics.accuracy_score(y_test, y_pred) * 100}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
